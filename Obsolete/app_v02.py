# app.py
import streamlit as st
from retrieval import check_fact_retrieval, get_wikipedia_article
from llm_checker import check_fact_llm
from utils import measure_latency, calculate_relevance
import time

st.set_page_config(page_title="Fakt-checker", layout="centered")
st.title("ğŸ” OvÄ›Å™ovaÄ faktÅ¯ (Fakt-checker)")

# API klice
openai_api_key = st.secrets.get("OPENAI_API_KEY")
groq_api_key = st.secrets.get("GROQ_API_KEY")

# Zadani tvrzeni
tvrzeni = st.text_input("Zadejte tvrzenÃ­, kterÃ© chcete ovÄ›Å™it:")

# Vyber metody
metoda = st.radio("Vyberte metodu ovÄ›Å™enÃ­:", ["KlasickÃ½ retrieval", "LLM - OpenAI GPT", "LLM - LLaMA (Groq)"])

# Inicializace session stavu pro fallback
if "fallback_word" not in st.session_state:
    st.session_state.fallback_word = ""

# Tlacitko pro spusteni
if st.button("OvÄ›Å™it fakt") and tvrzeni:
    st.write("---")
    st.subheader("ğŸ“„ TvrzenÃ­:")
    st.write(tvrzeni)

    if metoda == "KlasickÃ½ retrieval":
        with st.spinner("Analyzuji pomocÃ­ klasickÃ©ho retrievalu..."):
            start = time.time()
            verdict, source = check_fact_retrieval(tvrzeni)
            latency = measure_latency(start)

        if "ÄlÃ¡nek nenalezen" in verdict.lower():
            st.warning("NepodaÅ™ilo se automaticky najÃ­t relevantnÃ­ ÄlÃ¡nek na Wikipedii.")
            fallback = st.text_input("Zadejte vlastnÃ­ klÃ­ÄovÃ© slovo pro hledÃ¡nÃ­ ve Wikipedii:", key="fallback")
            if fallback:
                obsah = get_wikipedia_article(fallback)
                if obsah:
                    st.info(f"Nalezen ÄlÃ¡nek pro '{fallback}'. ZkouÅ¡Ã­m ovÄ›Å™it fakt...")
                    start = time.time()
                    verdict, source = check_fact_retrieval(f"{tvrzeni} {fallback}")
                    latency = measure_latency(start)
                else:
                    st.error("Ani ruÄnÄ› zadanÃ© slovo nevedlo k nalezenÃ­ ÄlÃ¡nku.")

        st.success(f"Verdikt: {verdict}")
        st.caption(f"Zdroj: {source}")
        st.caption(f"Latence: {latency:.2f} sekundy")

    else:
        model = "openai" if metoda == "LLM - OpenAI GPT" else "groq"
        with st.spinner(f"Dotazuji model {model.upper()}..."):
            start = time.time()
            verdict, answer, confidence = check_fact_llm(tvrzeni, model, openai_api_key, groq_api_key)
            latency = measure_latency(start)
            relevance = calculate_relevance(tvrzeni, answer)

        st.success(f"Verdikt: {verdict}")
        st.caption(f"OdpovÄ›Ä modelu: {answer}")
        st.caption(f"Latence: {latency:.2f} s")
        st.caption(f"DÅ¯leÅ¾itost odpovÄ›di (relevance): {relevance:.2f}")
        st.caption(f"Odhad jistoty: {confidence}")
