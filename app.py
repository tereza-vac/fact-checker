# app.py
import streamlit as st
from retrieval import retrieve_relevant_sentences
from duckduck_retrieval import duckduckgo_search
from llm_checker import check_fact_llm
from check_fact_rug import check_fact_rug
from utils import measure_latency, calculate_relevance
import time

st.set_page_config(page_title="Fakt-checker", layout="centered")
st.title("游댌 Ov캩콏ova캜 fakt콢")

# API klice
openai_api_key = st.secrets.get("OPENAI_API_KEY")
groq_api_key = st.secrets.get("GROQ_API_KEY")

# Zadani tvrzeni
tvrzeni = st.text_input("Zadejte tvrzen칤, kter칠 chcete ov캩콏it:")

# Vyber metody
metoda = st.radio(
    "Vyberte metodu ov캩콏en칤:",
    ["Klasick칳 retrieval", "LLM - OpenAI GPT", "LLM - LLaMA (Groq)", "LLM + Web (RUG)"]
)

if st.button("Ov캩콏it fakt") and tvrzeni:
    st.write("---")
    st.subheader("游늯 Tvrzen칤:")
    st.write(tvrzeni)

    if metoda == "Klasick칳 retrieval":
        with st.spinner("Vyhled치v치m relevantn칤 informace ze zdroj콢..."):
            start = time.time()
            tema, relevant_sentences = retrieve_relevant_sentences(tvrzeni)
            latency = measure_latency(start)

        if isinstance(relevant_sentences, str):
            st.warning("Nepoda콏ilo se naj칤t 캜l치nek na Wikipedii.")
        else:
            st.subheader("游눫 Nalezen칠 informace k tvrzen칤:")
            for i, (sentence, score) in enumerate(relevant_sentences):
                st.markdown(f"**{i+1}.** *{sentence}*  ")
                st.caption(f"Relevance sk칩re: {score}")

        st.caption(f"Latence: {latency:.2f} sekundy")

    elif metoda == "LLM + Web (RUG)":
        model = "openai" if st.radio("Model:", ["OpenAI GPT", "LLaMA (Groq)"]) == "OpenAI GPT" else "groq"
        with st.spinner("Z칤sk치v치m aktu치ln칤 informace z webu..."):
            start = time.time()
            kontext = duckduckgo_search(tvrzeni)
            verdict, comment, confidence = check_fact_rug(tvrzeni, model, openai_api_key, groq_api_key, kontext)
            latency = measure_latency(start)
            relevance = calculate_relevance(tvrzeni, comment)

        st.subheader("游깷 Kontext z webu:")
        for i, k in enumerate(kontext):
            st.markdown(f"**{i+1}.** {k}")

        st.success(f"Verdikt: {verdict}")
        st.markdown(f"**Koment치콏:** {comment}")
        st.caption(f"Latence: {latency:.2f} s")
        st.caption(f"Relevance koment치콏e: {relevance:.2f}")

    else:
        model = "openai" if metoda == "LLM - OpenAI GPT" else "groq"
        with st.spinner(f"Dotazuji model {model.upper()}..."):
            start = time.time()
            verdict, comment, confidence = check_fact_llm(tvrzeni, model, openai_api_key, groq_api_key)
            latency = measure_latency(start)
            relevance = calculate_relevance(tvrzeni, comment)

        st.success(f"Verdikt: {verdict}")
        st.markdown(f"**Koment치콏:** {comment}")
        st.caption(f"Latence: {latency:.2f} s")
        st.caption(f"D콢le쬴tost odpov캩di (relevance): {relevance:.2f}")
        st.caption(f"Odhad jistoty: {confidence}")
